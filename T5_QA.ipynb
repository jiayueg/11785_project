{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "T5_embed (1).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d880405c90fb4e8d9b22e2db072db699": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6017af8349ef4c68acc5e79963e62179",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_27fcc40cb6ae436f9a732c4f954e03fd",
              "IPY_MODEL_965bb273437a43beb5dd5b412d6ebe61",
              "IPY_MODEL_6b906ef1b28f4183933c6f09503dc87e"
            ]
          }
        },
        "6017af8349ef4c68acc5e79963e62179": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "27fcc40cb6ae436f9a732c4f954e03fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_92f5c9a06f9e4f139a9696265a34bde0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Validation sanity check:   0%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a44bff581e3c44e899c81b7c884678da"
          }
        },
        "965bb273437a43beb5dd5b412d6ebe61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8082b029a7b7450392f8ab191bd1ac59",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 2,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8f2a6f9bc2f1492cab52151a289c792e"
          }
        },
        "6b906ef1b28f4183933c6f09503dc87e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ec6f07767a1147dd872591d19b5309c9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/2 [00:01&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2690dbe8b48e4fd190f9ebc47e858aab"
          }
        },
        "92f5c9a06f9e4f139a9696265a34bde0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a44bff581e3c44e899c81b7c884678da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8082b029a7b7450392f8ab191bd1ac59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8f2a6f9bc2f1492cab52151a289c792e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ec6f07767a1147dd872591d19b5309c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2690dbe8b48e4fd190f9ebc47e858aab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "63b1786b62ae46ce904af7f293ba7069": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b0da0070e5024c14a6c4ef473cb1fb0b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f2ad6cc21add4f9b903a8e4c3543f055",
              "IPY_MODEL_36873ec9e05540caac33c445ce6b0091",
              "IPY_MODEL_960b1679092744cf98cab8ec97325a25"
            ]
          }
        },
        "b0da0070e5024c14a6c4ef473cb1fb0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "f2ad6cc21add4f9b903a8e4c3543f055": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f66ff0a167bf47bc8583c24fdc506a1d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Epoch 0:  28%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2c1702868e914140b7d35cca8c2fbb63"
          }
        },
        "36873ec9e05540caac33c445ce6b0091": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1a08ffe6ff06478d8f265004d8f25cf4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 211,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 60,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0174542c21b84a34baf0dd855bc45d00"
          }
        },
        "960b1679092744cf98cab8ec97325a25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c00815c31da141e492be8d8b356110c1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 60/211 [01:51&lt;04:41,  1.87s/it, loss=3.49, v_num=4, train_loss=2.760]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dbc704309b484ce58abfad17baa8f39a"
          }
        },
        "f66ff0a167bf47bc8583c24fdc506a1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2c1702868e914140b7d35cca8c2fbb63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1a08ffe6ff06478d8f265004d8f25cf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0174542c21b84a34baf0dd855bc45d00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c00815c31da141e492be8d8b356110c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dbc704309b484ce58abfad17baa8f39a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4f984c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "385affa4-07ed-4f1d-86c2-fb04c63216bf"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!pip install transformers datasets pytorch_lightning rouge_score nltk\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import transformers\n",
        "import datasets\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import json\n",
        "import re\n",
        "from torch.nn import CrossEntropyLoss, MultiheadAttention\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
        "import pytorch_lightning as pl\n",
        "from datasets import load_dataset, load_metric, concatenate_datasets\n",
        "from transformers import (\n",
        "     AdamW,\n",
        "     T5ForConditionalGeneration,\n",
        "     T5Tokenizer,\n",
        "     get_linear_schedule_with_warmup,\n",
        "     AlbertConfig,\n",
        "     AlbertModel,\n",
        "     AlbertTokenizer,\n",
        "     AlbertTokenizerFast,\n",
        "     get_constant_schedule_with_warmup,\n",
        "     get_cosine_schedule_with_warmup,\n",
        " )\n",
        "from transformers.modeling_outputs import MultipleChoiceModelOutput\n",
        "from functools import partial\n",
        "from typing import Optional, Dict\n",
        "from rouge_score import rouge_scorer\n",
        "from utils import load_data, load_data_workhorse"
      ],
      "id": "f4f984c0",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.12.5)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (1.16.1)\n",
            "Requirement already satisfied: pytorch_lightning in /usr/local/lib/python3.7/dist-packages (1.5.3)\n",
            "Requirement already satisfied: rouge_score in /usr/local/lib/python3.7/dist-packages (0.0.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.1.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n",
            "Requirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2021.11.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (2.7.0)\n",
            "Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (1.10.0+cu111)\n",
            "Requirement already satisfied: pyDeprecate==0.3.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (0.3.1)\n",
            "Requirement already satisfied: future>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (0.18.2)\n",
            "Requirement already satisfied: torchmetrics>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (0.6.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.42.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.35.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.12.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.0.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.37.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.8.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (3.17.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (57.4.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.4.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard>=2.2.0->pytorch_lightning) (1.15.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (4.7.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning) (1.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning) (3.1.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.2.0)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (5.2.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.7)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.7.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6vNks_E0JK4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f41f5afb-7aa2-40d3-9190-b7f2f2cbb1fe"
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "id": "F6vNks_E0JK4",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e650a827"
      },
      "source": [
        "# Load TOEFL dataset"
      ],
      "id": "e650a827"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5a1cc94"
      },
      "source": [
        "train_data, dev_data, test_data = load_data(\"/content/gdrive/MyDrive/TOEFL-QA-master/data\")"
      ],
      "id": "b5a1cc94",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "557d05de"
      },
      "source": [
        "def convert_form(data_dict):\n",
        "    new_dict = {}\n",
        "    new_dict[\"sentences_word\"] = [] #each word is treated spereately and sentence is viewed as a list\n",
        "    new_dict[\"sentences_join\"] = [] #words in sentence are joined, each sentence is viewed as a string\n",
        "    new_dict[\"questions_word\"] = []\n",
        "    new_dict[\"questions_join\"] = []\n",
        "    new_dict[\"answers_word\"] = []\n",
        "    new_dict[\"answers_join\"] = []\n",
        "    new_dict[\"options_word\"] = [] #should be a list of list, word-level\n",
        "    new_dict[\"options_join\"] = []\n",
        "    new_dict[\"context\"] = []\n",
        "    for file in data_dict.keys():\n",
        "        #can also have word-based version\n",
        "        new_dict[\"sentences_word\"].append(data_dict[file][\"sentences\"])\n",
        "        sentences_list = [(lambda words_list: ' '.join(words_list)) (words_list) for words_list in data_dict[file][\"sentences\"]]\n",
        "        new_dict[\"sentences_join\"].append(sentences_list)\n",
        "        new_dict[\"context\"] = [(lambda sentence_list: ' '.join(sentence_list)) (sentence_list) for sentence_list in new_dict[\"sentences_join\"]]\n",
        "        \n",
        "        new_dict['questions_join'].append(\" \".join(data_dict[file][\"question\"]))\n",
        "        new_dict['questions_word'].append(data_dict[file][\"question\"])\n",
        "        \n",
        "        new_dict['answers_join'].append(\" \".join(data_dict[file][\"answer\"]))\n",
        "        new_dict['answers_word'].append(data_dict[file][\"answer\"])\n",
        "        \n",
        "        new_dict[\"options_join\"].append([(lambda words_list: ' '.join(words_list)) (words_list) for words_list in data_dict[file][\"options\"]])\n",
        "        new_dict[\"options_word\"].append(data_dict[file][\"options\"])\n",
        "    return new_dict"
      ],
      "id": "557d05de",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "8667a2f4"
      },
      "source": [
        "train_transform = convert_form(train_data)\n",
        "dev_transform = convert_form(dev_data)\n",
        "test_transform = convert_form(test_data)"
      ],
      "id": "8667a2f4",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRk8onmcmIap"
      },
      "source": [
        "f = open(\"/content/gdrive/MyDrive/RACE/train_race_middle.json\", 'r')\n",
        "train_race_middle = json.load(f)\n",
        "f = open(\"/content/gdrive/MyDrive/RACE/train_race_high.json\", 'r')\n",
        "train_race_high = json.load(f)\n",
        "f = open(\"/content/gdrive/MyDrive/RACE/val_race_high.json\", 'r')\n",
        "val_race_high = json.load(f)\n",
        "f = open(\"/content/gdrive/MyDrive/RACE/val_race_middle.json\", 'r')\n",
        "val_race_middle = json.load(f)"
      ],
      "id": "fRk8onmcmIap",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fObSU0FCkDVh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "84b1887f-0a95-4ace-eed8-0e507dc5d5a2"
      },
      "source": [
        "train_transform['questions_join'][0]"
      ],
      "id": "fObSU0FCkDVh",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'based on the conversation , what can be conducted about dialect accommodation'"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVOu64J0ndCs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5887cded-5097-452d-bb08-23a3f40e050e"
      },
      "source": [
        "train_race_middle['questions_join'][0]"
      ],
      "id": "aVOu64J0ndCs",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'What does Robbie want to do on the rainy day ? '"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DYG32_rkJmy"
      },
      "source": [
        "def merge_datasets(datasets):\n",
        "  new_dict = {}\n",
        "  for key in datasets[0].keys():\n",
        "    new_dict[key] = []\n",
        "    for d in datasets:\n",
        "      assert(key in d)\n",
        "      new_dict[key] += d[key]\n",
        "  return new_dict"
      ],
      "id": "9DYG32_rkJmy",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgarVPpuk-UI"
      },
      "source": [
        "combined_train = merge_datasets([train_transform, train_race_middle, train_race_high])\n",
        "combined_val = merge_datasets([dev_transform, val_race_middle, val_race_high])\n",
        "# train = datasets.Dataset.from_dict(combined_train)\n",
        "# val = datasets.Dataset.from_dict(combined_val)\n",
        "# test = datasets.Dataset.from_dict(test_transform)\n",
        "train = datasets.Dataset.from_dict(train_transform)\n",
        "val = datasets.Dataset.from_dict(dev_transform)\n",
        "test = datasets.Dataset.from_dict(test_transform)"
      ],
      "id": "XgarVPpuk-UI",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "faf2a163"
      },
      "source": [
        "# tokenize the input"
      ],
      "id": "faf2a163"
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "d3867472",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26c00429-3d7f-44a8-be95-77c63d8925b6"
      },
      "source": [
        "from transformers import AutoTokenizer, T5Tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")\n",
        "print(tokenizer)"
      ],
      "id": "d3867472",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PreTrainedTokenizerFast(name_or_path='t5-small', vocab_size=32100, model_max_len=512, is_fast=True, padding_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>']})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYhe5p65L2QZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdf35cf6-6e51-4485-8703-c77d090310b3"
      },
      "source": [
        "train"
      ],
      "id": "cYhe5p65L2QZ",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['sentences_word', 'sentences_join', 'questions_word', 'questions_join', 'answers_word', 'answers_join', 'options_word', 'options_join', 'context'],\n",
              "    num_rows: 717\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFSyiAa_HkWl",
        "outputId": "35c2e85d-1b71-4dd9-a368-b59de25651ae"
      },
      "source": [
        "len(train['questions_join'])"
      ],
      "id": "cFSyiAa_HkWl",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "717"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0NjruoVQjmY",
        "outputId": "aaaab468-54cf-48fa-cc3a-579915b6a647"
      },
      "source": [
        "train.num_rows"
      ],
      "id": "j0NjruoVQjmY",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "717"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f11df8d6"
      },
      "source": [
        "# Tokenize And Encode Answer As Target"
      ],
      "id": "f11df8d6"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d79a50ff"
      },
      "source": [
        "answer_encoding = tokenizer(\n",
        "     train['answers_join'],\n",
        "     max_length=24,\n",
        "     padding='max_length',\n",
        "     truncation=True,\n",
        "     return_attention_mask=True,\n",
        " )\n",
        " \n",
        "labels = answer_encoding[\"input_ids\"]"
      ],
      "id": "d79a50ff",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03e8929e"
      },
      "source": [
        "#define pytorch dataset for TOEFL-QA\n",
        "class BioQADataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        dataframe,\n",
        "        tokenizer:T5Tokenizer,\n",
        "        source_max_token_len: int = 396,\n",
        "        source_stride: int = 128,\n",
        "        target_max_token_len: int = 32,\n",
        "    ):\n",
        "        self.dataframe = dataframe\n",
        "        self.tokenizer = tokenizer\n",
        "        self.source_max_token_len =  source_max_token_len\n",
        "        self.source_stride = source_stride\n",
        "        self.target_max_token_len =  target_max_token_len\n",
        "        \n",
        "        #tokenize input\n",
        "        self.source_encoding = tokenizer(\n",
        "            self.dataframe[\"questions_join\"],\n",
        "            self.dataframe[\"context\"],\n",
        "            truncation=\"only_second\",\n",
        "            max_length=self.source_max_token_len,\n",
        "            return_overflowing_tokens=True,\n",
        "            return_offsets_mapping=True,\n",
        "            return_attention_mask=True,\n",
        "            stride=self.source_stride,\n",
        "            padding=\"max_length\",\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "        \n",
        "        #tokenize output\n",
        "        self.target_encoding = tokenizer(\n",
        "            self.dataframe[\"answers_join\"],\n",
        "            truncation=True,\n",
        "            max_length=self.target_max_token_len,\n",
        "            padding='max_length',\n",
        "            return_attention_mask=True,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "        #this is the mapping from indices of samples to indices of question\n",
        "        self.sample2indices = self.source_encoding.pop(\"overflow_to_sample_mapping\")\n",
        "        \n",
        "    def __len__(self):\n",
        "        return(self.dataframe.num_rows)\n",
        "    \n",
        "    def __getitem__(self, idx: int):\n",
        "        label_idx = self.sample2indices[idx] # index of corresponding label\n",
        "        labels = self.target_encoding['input_ids'][label_idx]\n",
        "        labels[labels==0] = -100\n",
        "        \n",
        "        return dict(\n",
        "            question=self.dataframe[idx][\"questions_join\"],\n",
        "            context=self.dataframe[idx]['context'],\n",
        "            answer=self.dataframe[idx]['answers_join'],\n",
        "            input_ids=self.source_encoding[\"input_ids\"][idx].flatten(),\n",
        "            attention_mask=self.source_encoding['attention_mask'][idx].flatten(),\n",
        "            labels=labels.flatten(),\n",
        "        )"
      ],
      "id": "03e8929e",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVfibUGTQE-m"
      },
      "source": [
        "train_dataset = BioQADataset(train, tokenizer, 396, 128, 32)"
      ],
      "id": "jVfibUGTQE-m",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dc5c9PGtQqua",
        "outputId": "5c695466-5226-46c2-9702-8f0bbf05bae2"
      },
      "source": [
        "len(train_dataset)"
      ],
      "id": "Dc5c9PGtQqua",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "717"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44bcf19b"
      },
      "source": [
        "class BioDataModule(pl.LightningDataModule):\n",
        "    def __init__(\n",
        "        self,\n",
        "        train_data,\n",
        "        dev_data,\n",
        "        test_data,\n",
        "        tokenizer:T5Tokenizer,\n",
        "        batch_size: int = 8,\n",
        "        source_max_token_len: int = 396,\n",
        "        source_stride: int = 128,\n",
        "        target_max_token_len: int = 32,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.train_data = train_data\n",
        "        self.dev_data = dev_data\n",
        "        self.test_data = test_data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.batch_size = batch_size\n",
        "        self.source_max_token_len = source_max_token_len\n",
        "        self.source_stride = source_stride\n",
        "        self.target_max_token_len = target_max_token_len\n",
        "        \n",
        "    def setup(self):\n",
        "        self.train_dataset = BioQADataset(\n",
        "            self.train_data,\n",
        "            self.tokenizer,\n",
        "            self.source_max_token_len,\n",
        "            self.source_stride,\n",
        "            self.target_max_token_len,\n",
        "        )\n",
        "        self.dev_dataset = BioQADataset(\n",
        "            self.dev_data,\n",
        "            self.tokenizer,\n",
        "            self.source_max_token_len,\n",
        "            self.source_stride,\n",
        "            self.target_max_token_len,\n",
        "        )\n",
        "        self.test_dataset = BioQADataset(\n",
        "            self.test_data,\n",
        "            self.tokenizer,\n",
        "            self.source_max_token_len,\n",
        "            self.source_stride,\n",
        "            self.target_max_token_len,\n",
        "        )\n",
        "        \n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.train_dataset,\n",
        "            batch_size=self.batch_size,\n",
        "            shuffle=True,\n",
        "            num_workers=4,\n",
        "        )\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.dev_dataset,\n",
        "            batch_size=self.batch_size,\n",
        "            num_workers=4,\n",
        "        )\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.test_dataset,\n",
        "            batch_size=1,\n",
        "            num_workers=4,\n",
        "        )"
      ],
      "id": "44bcf19b",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53b9eda5"
      },
      "source": [
        "BATCH_SIZE = 4\n",
        "N_EPOCHS = 6\n",
        "data_module = BioDataModule(train, val, test, tokenizer, batch_size=BATCH_SIZE)\n",
        "data_module.setup()"
      ],
      "id": "53b9eda5",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b93ccd18"
      },
      "source": [
        "#model definition\n",
        "class QAModel(pl.LightningModule):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = T5ForConditionalGeneration.from_pretrained(\"t5-small\", return_dict=True)\n",
        "    \n",
        "    def forward(self, input_ids, attention_mask, labels=None):\n",
        "        output = self.model(\n",
        "            input_ids, \n",
        "            attention_mask=attention_mask,\n",
        "            labels=labels\n",
        "        )\n",
        "        return output.loss, output.logits\n",
        "    \n",
        "    def training_step(self, batch, batch_idx):\n",
        "        input_ids = batch['input_ids']\n",
        "        attention_mask=batch['attention_mask']\n",
        "        labels = batch['labels']\n",
        "        loss, outputs = self(input_ids, attention_mask, labels)\n",
        "        self.log(\"train_loss\", loss, prog_bar=True, logger=True)\n",
        "        return {\"loss\": loss, \"predictions\":outputs, \"labels\": labels}\n",
        "    \n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        input_ids = batch['input_ids']\n",
        "        attention_mask=batch['attention_mask']\n",
        "        labels = batch['labels']\n",
        "        loss, outputs = self(input_ids, attention_mask, labels)\n",
        "        self.log(\"val_loss\", loss, prog_bar=True, logger=True)\n",
        "        return loss\n",
        "    \n",
        "    def test_step(self, batch, batch_idx):\n",
        "        input_ids = batch['input_ids']\n",
        "        attention_mask=batch['attention_mask']\n",
        "        labels = batch['labels']\n",
        "        loss, outputs = self(input_ids, attention_mask, labels)\n",
        "        self.log(\"test_loss\", loss, prog_bar=True, logger=True)\n",
        "        return loss\n",
        "    \n",
        "    def configure_optimizers(self):\n",
        "        optimizer = AdamW(self.parameters(), lr=0.0001)\n",
        "        return optimizer\n"
      ],
      "id": "b93ccd18",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "754d1ed7"
      },
      "source": [
        "# genrating answer"
      ],
      "id": "754d1ed7"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2349b585",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 518,
          "referenced_widgets": [
            "d880405c90fb4e8d9b22e2db072db699",
            "6017af8349ef4c68acc5e79963e62179",
            "27fcc40cb6ae436f9a732c4f954e03fd",
            "965bb273437a43beb5dd5b412d6ebe61",
            "6b906ef1b28f4183933c6f09503dc87e",
            "92f5c9a06f9e4f139a9696265a34bde0",
            "a44bff581e3c44e899c81b7c884678da",
            "8082b029a7b7450392f8ab191bd1ac59",
            "8f2a6f9bc2f1492cab52151a289c792e",
            "ec6f07767a1147dd872591d19b5309c9",
            "2690dbe8b48e4fd190f9ebc47e858aab",
            "63b1786b62ae46ce904af7f293ba7069",
            "b0da0070e5024c14a6c4ef473cb1fb0b",
            "f2ad6cc21add4f9b903a8e4c3543f055",
            "36873ec9e05540caac33c445ce6b0091",
            "960b1679092744cf98cab8ec97325a25",
            "f66ff0a167bf47bc8583c24fdc506a1d",
            "2c1702868e914140b7d35cca8c2fbb63",
            "1a08ffe6ff06478d8f265004d8f25cf4",
            "0174542c21b84a34baf0dd855bc45d00",
            "c00815c31da141e492be8d8b356110c1",
            "dbc704309b484ce58abfad17baa8f39a"
          ]
        },
        "outputId": "52488fdb-4c3c-48ed-ad41-b5561f07ac37"
      },
      "source": [
        "model = QAModel()\n",
        "\n",
        "trainer = pl.Trainer(\n",
        "     max_epochs=20,\n",
        "     gpus=0,\n",
        "     progress_bar_refresh_rate = 30\n",
        " )\n",
        "trainer.fit(model, data_module)"
      ],
      "id": "2349b585",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/connectors/callback_connector.py:91: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=30)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.\n",
            "  f\"Setting `Trainer(progress_bar_refresh_rate={progress_bar_refresh_rate})` is deprecated in v1.5 and\"\n",
            "GPU available: True, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py:1580: UserWarning: GPU available but not used. Set the gpus flag in your trainer `Trainer(gpus=1)` or script `--gpus=1`.\n",
            "  \"GPU available but not used. Set the gpus flag in your trainer `Trainer(gpus=1)` or script `--gpus=1`.\"\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/datamodule.py:470: LightningDeprecationWarning: DataModule.setup has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.setup.\n",
            "  f\"DataModule.{name} has already been called, so it will not be called again. \"\n",
            "\n",
            "  | Name  | Type                       | Params\n",
            "-----------------------------------------------------\n",
            "0 | model | T5ForConditionalGeneration | 60.5 M\n",
            "-----------------------------------------------------\n",
            "60.5 M    Trainable params\n",
            "0         Non-trainable params\n",
            "60.5 M    Total params\n",
            "242.026   Total estimated model params size (MB)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d880405c90fb4e8d9b22e2db072db699",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Validation sanity check: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:60: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 42. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
            "  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:60: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 68. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
            "  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "63b1786b62ae46ce904af7f293ba7069",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/optimization/closure.py:36: LightningDeprecationWarning: One of the returned values {'predictions', 'labels'} has a `grad_fn`. We will detach it automatically but this behaviour will change in v1.6. Please detach it manually: `return {'loss': ..., 'something': something.detach()}`\n",
            "  f\"One of the returned values {set(extra.keys())} has a `grad_fn`. We will detach it automatically\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxT26ZiCRoFW"
      },
      "source": [
        "!watch -n 0.2 nvidia-smi"
      ],
      "id": "LxT26ZiCRoFW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1a46490a"
      },
      "source": [
        "# question answering example"
      ],
      "id": "1a46490a"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5546cf9"
      },
      "source": [
        "i = 5\n",
        "\n",
        "source_encoding=tokenizer(\n",
        "       test[i][\"questions_join\"],\n",
        "       test[i]['context'],\n",
        "       max_length = 396,\n",
        "       padding=\"max_length\",\n",
        "       truncation=\"only_second\",\n",
        "       return_attention_mask=True,\n",
        "       add_special_tokens=True,\n",
        "       return_tensors=\"pt\"\n",
        "   )\n",
        "generated_ids = model.model.generate(\n",
        "       input_ids=source_encoding[\"input_ids\"],\n",
        "       attention_mask=source_encoding[\"attention_mask\"],\n",
        "       num_beams=1,  # greedy search\n",
        "       max_length=24,\n",
        "       repetition_penalty=2.5,\n",
        "       early_stopping=True,\n",
        "       use_cache=True\t\n",
        ")"
      ],
      "id": "d5546cf9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5284c0fd"
      },
      "source": [
        "preds = [tokenizer.decode(generated_id, skip_special_tokens=True, clean_up_tokenization_spaces=True) for generated_id in generated_ids]"
      ],
      "id": "5284c0fd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c50eecdf"
      },
      "source": [
        "print(\" \".join(preds))"
      ],
      "id": "c50eecdf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ddb24fe"
      },
      "source": [
        "print(test[i][\"questions_join\"])\n",
        "print(test[i][\"context\"])\n",
        "print(test[i][\"answers_join\"])"
      ],
      "id": "9ddb24fe",
      "execution_count": null,
      "outputs": []
    }
  ]
}