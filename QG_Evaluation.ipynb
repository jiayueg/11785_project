{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "QG Evaluation",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_EV9kOrfT4c"
      },
      "source": [
        "% mkdir data\n",
        "% cd data\n",
        "! git clone https://github.com/iamyuanchung/TOEFL-QA.git\n",
        "% cd .."
      ],
      "id": "9_EV9kOrfT4c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eo0lO1vLzKJB"
      },
      "source": [
        "! pip install transformers\n",
        "! pip install sentencepiece\n",
        "! pip install rouge-score\n",
        "! pip install -U nltk"
      ],
      "id": "eo0lO1vLzKJB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85fa624c"
      },
      "source": [
        "# Imports"
      ],
      "id": "85fa624c"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5421ee36"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import spacy\n",
        "from tqdm.notebook import tqdm\n",
        "import re\n",
        "from pprint import pprint\n",
        "import sentencepiece\n",
        "import nltk\n",
        "from rouge_score import rouge_scorer\n",
        "nltk.download('all')\n",
        "from nltk.translate import meteor_score"
      ],
      "id": "5421ee36",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eb4367c"
      },
      "source": [
        "from transformers import T5Tokenizer, T5ForConditionalGeneration, T5Config"
      ],
      "id": "7eb4367c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1133101"
      },
      "source": [
        "import importlib\n",
        "util = importlib.import_module(\"data.TOEFL-QA.utils\")\n",
        "TOEFL_PATH = \"./data/TOEFL-QA/data/\"\n",
        "raw = util.load_data(TOEFL_PATH)\n",
        "train_raw, dev_raw, test_raw = tuple(raw)"
      ],
      "id": "f1133101",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "211e8538"
      },
      "source": [
        "# Options"
      ],
      "id": "211e8538"
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "75537326",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ee4dbfb-c83f-4508-dc41-841f6dcfa96d"
      },
      "source": [
        "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device = torch.device('cpu')\n",
        "print('Using device:', device)"
      ],
      "id": "75537326",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "858624b1"
      },
      "source": [
        "PRETRAINED_MODEL = 't5-base'\n",
        "DIR = \"question_generator/\"\n",
        "BATCH_SIZE = 1\n",
        "SEQ_LENGTH = 512\n",
        "EPOCHS = 200\n",
        "USE_ANSWERS = False"
      ],
      "id": "858624b1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwWxVaNuRNrj"
      },
      "source": [
        "from transformers import T5Tokenizer, T5ForConditionalGeneration, T5Config\n",
        "qg_model = T5ForConditionalGeneration.from_pretrained('t5-base')"
      ],
      "id": "YwWxVaNuRNrj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7c0c949"
      },
      "source": [
        "# Utility Functions"
      ],
      "id": "e7c0c949"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3705201"
      },
      "source": [
        "def get_sent_str(sentence_list):\n",
        "    sent = \" \".join(sentence_list)\n",
        "    sent = re.sub(r\" (?P<punc>[.?,])\", r\"\\1\", sent)\n",
        "    return sent\n",
        "\n",
        "def get_sent_list(sentences):\n",
        "    sent_list = []\n",
        "    for sent in sentences:\n",
        "        sent_list.append(get_sent_str(sent))\n",
        "    return sent_list"
      ],
      "id": "d3705201",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "557906b1"
      },
      "source": [
        "def get_contexts(sentences):\n",
        "    out = []\n",
        "    for i in range(3, len(sentences)+1):\n",
        "        out.append(\" \".join([get_sent_str(sent) for sent in sentences[i-3:i]]))\n",
        "    return out\n",
        "\n",
        "def encode_contexts(inputs, answers=None):\n",
        "    out = []\n",
        "    for i in range(len(inputs)):\n",
        "        s = \"\"\n",
        "        if USE_ANSWERS:\n",
        "            s = '<answer> ' + inputs[i] + \" <context> \" + answers[i]\n",
        "        else:\n",
        "            s = inputs[i]\n",
        "        out.append(tokenizer(\n",
        "            s, \n",
        "            pad_to_max_length=True, \n",
        "            max_length=SEQ_LENGTH,\n",
        "            truncation=True,\n",
        "            return_tensors=\"pt\"\n",
        "        ))\n",
        "    return out"
      ],
      "id": "557906b1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2d07966c"
      },
      "source": [
        "# Tokenizer Downloaded"
      ],
      "id": "2d07966c"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0e25165"
      },
      "source": [
        "tokenizer = T5Tokenizer.from_pretrained(PRETRAINED_MODEL)\n",
        "tokenizer.add_special_tokens(\n",
        "    {'additional_special_tokens': ['<answer>', '<context>']}\n",
        ");"
      ],
      "id": "d0e25165",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0764b187"
      },
      "source": [
        "# Evaluation of Model"
      ],
      "id": "0764b187"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51e4a7f2"
      },
      "source": [
        "def all_tpos(raw_data):\n",
        "  result = dict()\n",
        "  for sentence in raw_data.keys():\n",
        "    digits = re.findall(r'\\d+', sentence)\n",
        "    types = 'conversation' if 'conversation' in sentence else 'lecture'\n",
        "    name = 'tpo_' + digits[0] + \"-\" + types + \"_\" + digits[1]\n",
        "    if name in result.keys():\n",
        "      result[name] = result[name] + [digits[2]]\n",
        "    else:\n",
        "      result[name] = [digits[2]]\n",
        "  return result\n",
        "\n",
        "def evaluate_model(model, dev_raw, print_detail = False):\n",
        "  model.to(device)\n",
        "  model.eval()\n",
        "  raw_tpos = all_tpos(dev_raw)\n",
        "  bleu_total = []\n",
        "  meteor_total = []\n",
        "  rouge_total = []\n",
        "  scorer = rouge_scorer.RougeScorer(['rouge1'], use_stemmer=True)\n",
        "  for sentence in raw_tpos.keys():\n",
        "    question = raw_tpos[sentence][0]\n",
        "    sentence = sentence + \"_\" + question\n",
        "    contexts = get_contexts(dev_raw[sentence][\"sentences\"])\n",
        "    encoded_contexts = encode_contexts(contexts)\n",
        "    questions = []\n",
        "    for i in encoded_contexts:\n",
        "      question = model.generate(input_ids=i[\"input_ids\"])\n",
        "      questions.append(tokenizer.decode(question[0], skip_special_tokens=True))\n",
        "    ground_truth = [get_sent_str(dev_raw[i]['question']) for i in dev_raw.keys() if i.startswith(sentence)]\n",
        "    bleus = []\n",
        "    meteors = []\n",
        "    rouges = []\n",
        "    bar = tqdm(total = len(questions))\n",
        "    for generated in questions:\n",
        "      highest_bleu = 0.0\n",
        "      highest_meteor = 0.0\n",
        "      highest_rouge = 0.0\n",
        "      for qs in ground_truth:\n",
        "        r_score = scorer.score(qs, generated)\n",
        "        rouge = r_score['rouge1'][2]\n",
        "        generated = generated.split(\" \")\n",
        "        qs = qs.split(\" \")\n",
        "        bleu = nltk.translate.bleu_score.sentence_bleu(qs, generated)\n",
        "        meteor = nltk.translate.meteor_score.meteor_score([qs], generated)\n",
        "        if bleu > highest_bleu:\n",
        "          highest_bleu = bleu\n",
        "        if meteor > highest_meteor:\n",
        "          highest_meteor = meteor\n",
        "        if rouge > highest_rouge:\n",
        "          highesr_rouge = rouge\n",
        "      bleus.append(highest_bleu)\n",
        "      meteors.append(highest_meteor)\n",
        "      rouges.append(highest_rouge)\n",
        "      bar.update(1)\n",
        "    result = [\n",
        "              {\n",
        "                  'generated_question' : question,\n",
        "                  'bleu_score' : bleu, \n",
        "                  'meteor_score' : meteor, \n",
        "                  'rouge_score' : rouge\n",
        "              } for question, bleu_score, meteor_score, rouge in zip(questions, bleus, meteors, rouges)\n",
        "             ]\n",
        "    if print_detail:\n",
        "      print(result)\n",
        "    bleu_total.append(sum(bleus) / len(bleus))\n",
        "    meteor_total.append(sum(meteors) / len(meteors))\n",
        "    rouge_total.append(sum(rouges) / len(rouges))\n",
        "  return bleu_total, meteor_total, rouge_total"
      ],
      "id": "51e4a7f2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OX-m4IUcSDdR"
      },
      "source": [
        "evaluate_model(qg_model, dev_raw, True)"
      ],
      "id": "OX-m4IUcSDdR",
      "execution_count": null,
      "outputs": []
    }
  ]
}