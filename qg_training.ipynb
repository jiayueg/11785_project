{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/AMontgomerie/question_generator/blob/master/training/qg_training.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FvBm_K5WnVj9"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import spacy\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UDaysJyJytAs"
   },
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, T5Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset race (C:\\Users\\Kevin\\.cache\\huggingface\\datasets\\race\\high\\0.1.0\\5a80ba2d003e023fdce95d01c1b02f5a70d5eb2375465bee162baf9824c91474)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbb11b222b84499b9688b20b0b6fe218",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"race\", \"high\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'example_id': 'high1.txt',\n",
       " 'article': 'My husband is a born shopper. He loves to look at things and to touch them. He likes to compare prices between the same items in different shops. He would never think of buying anything without looking around in several different shops. On the other hand, I\\'m not a shopper. I think shopping is boring and unpleasant. If I like something and I have enough money to take it, I buy it at once. I never look around for a good price or a better deal. Of course my husband and I never go shopping together. Doing shopping together would be too painful for both of us. When it comes to shopping, we go our different ways.\\nSometimes I ask my son Jimmy to buy some food in the shop not far from our home. But he is always absent-minded. This was his story.\\nOne day I said to him, \" I hope you won\\'t forget what I have told you to buy.\" \" No,\" said Jimmy. \"I won\\'t forget. You want three oranges , six eggs and a pound of meat.\"\\nHe went running down the street to the shop. As he ran, he said to himself over and over again, \"three oranges , six eggs and a pound of meat.\"\\nIn the beginning he remembered everything but he stopped several times. Once he saw two men fighting outside a clothes shop until a policeman stopped them. One of them was badly hurt. Then he stopped to give ten cents to a beggar. Then he met some of his friends and he played with them for a while. When he reached the shop, he had forgotten everything except six eggs.\\nAs he walked home, his face became sadder and sadder. When he saw me he said, \"I\\'m sorry, Mum. I have forgotten to buy oranges and the meat. I only remembered to buy six eggs, but I\\'ve dropped three of them.\"',\n",
       " 'answer': 'C',\n",
       " 'question': 'The husband likes shopping because   _  .',\n",
       " 'options': ['he has much money.',\n",
       "  'he likes the shops.',\n",
       "  'he likes to compare the prices between the same items.',\n",
       "  'he has nothing to do but shopping.']}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dataset[\"train\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PzW_zmk2qFHG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s-IgF44jMFPY"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PRETRAINED_MODEL = 't5-base'\n",
    "DIR = \"question_generator/\"\n",
    "BATCH_SIZE = 1\n",
    "SEQ_LENGTH = 512\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(PRETRAINED_MODEL)\n",
    "tokenizer.add_special_tokens(\n",
    "    {'additional_special_tokens': ['<answer>', '<context>']}\n",
    ")\n",
    "\n",
    "# class QGDataset(Dataset):\n",
    "#     def __init__(self, csv):\n",
    "#         self.df = pd.read_csv(csv, engine='python')\n",
    "\n",
    "#     def __len__(self):\n",
    "#          return len(self.df)\n",
    "\n",
    "#     def __getitem__(self, idx):   \n",
    "#         if torch.is_tensor(idx):\n",
    "#             idx = idx.tolist()\n",
    "#         row = self.df.iloc[idx, 1:]       \n",
    "\n",
    "#         encoded_text = tokenizer(\n",
    "#             row['text'], \n",
    "#             pad_to_max_length=True, \n",
    "#             max_length=SEQ_LENGTH,\n",
    "#             truncation=True,\n",
    "#             return_tensors=\"pt\"\n",
    "#         )\n",
    "#         encoded_text['input_ids'] = torch.squeeze(encoded_text['input_ids'])\n",
    "#         encoded_text['attention_mask'] = torch.squeeze(encoded_text['attention_mask'])\n",
    "\n",
    "#         encoded_question = tokenizer(\n",
    "#             row['question'],\n",
    "#             pad_to_max_length=True,\n",
    "#             max_length=SEQ_LENGTH,\n",
    "#             truncation=True,\n",
    "#             return_tensors='pt'\n",
    "#         )\n",
    "#         encoded_question['input_ids'] = torch.squeeze(encoded_question['input_ids'])\n",
    "\n",
    "#         return (encoded_text.to(device), encoded_question.to(device))\n",
    "\n",
    "# train_set = QGDataset(os.path.join(DIR, 'question_generator/datasets/qg_train.csv'))\n",
    "# train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "# valid_set = QGDataset(os.path.join(DIR, 'question_generator/datasets/qg_valid.csv')) \n",
    "# valid_loader = DataLoader(valid_set, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\Kevin\\.cache\\huggingface\\datasets\\race\\high\\0.1.0\\5a80ba2d003e023fdce95d01c1b02f5a70d5eb2375465bee162baf9824c91474\\cache-7069e3a27b93c19d.arrow\n",
      "Loading cached processed dataset at C:\\Users\\Kevin\\.cache\\huggingface\\datasets\\race\\high\\0.1.0\\5a80ba2d003e023fdce95d01c1b02f5a70d5eb2375465bee162baf9824c91474\\cache-dc6faf71a15bd577.arrow\n",
      "Loading cached processed dataset at C:\\Users\\Kevin\\.cache\\huggingface\\datasets\\race\\high\\0.1.0\\5a80ba2d003e023fdce95d01c1b02f5a70d5eb2375465bee162baf9824c91474\\cache-d8c2afa6b62f65ed.arrow\n"
     ]
    }
   ],
   "source": [
    "def make_text(row):    \n",
    "    encoded = {}\n",
    "    encoded_text = tokenizer(\n",
    "        row['answer'] + row['article'], \n",
    "        pad_to_max_length=True, \n",
    "        max_length=SEQ_LENGTH,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    encoded['input_ids'] = torch.squeeze(encoded_text['input_ids'])\n",
    "    encoded['attention_mask'] = torch.squeeze(encoded_text['attention_mask'])\n",
    "\n",
    "    encoded_question = tokenizer(\n",
    "        row['question'],\n",
    "        pad_to_max_length=True,\n",
    "        max_length=SEQ_LENGTH,\n",
    "        truncation=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    encoded['input_ids_question'] = torch.squeeze(encoded_question['input_ids'])\n",
    "    return encoded\n",
    "\n",
    "dataset = dataset.map(make_text)\n",
    "dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'input_ids_question'])\n",
    "train_loader = DataLoader(dataset[\"train\"], batch_size=BATCH_SIZE, shuffle=True)\n",
    "valid_loader = DataLoader(dataset[\"validation\"], batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NJrb9kYNz_wz"
   },
   "outputs": [],
   "source": [
    "LR = 0.001\n",
    "EPOCHS = 20\n",
    "LOG_INTERVAL = 5000\n",
    "\n",
    "config = T5Config(decoder_start_token_id=tokenizer.pad_token_id)\n",
    "model = T5ForConditionalGeneration(config).from_pretrained(PRETRAINED_MODEL)\n",
    "model.resize_token_embeddings(len(tokenizer)) # to account for new special tokens\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rcfRh2JC0CF1"
   },
   "outputs": [],
   "source": [
    "SAVED_MODEL_PATH = \"question_generator/qg_pretrained_t5_model_trained.pth\"\n",
    "\n",
    "def train(epoch, best_val_loss):\n",
    "    model.train()\n",
    "    total_loss = 0.\n",
    "    for batch_index, batch in tqdm(enumerate(train_loader)):\n",
    "        target = {\n",
    "            'input_ids': batch['input_ids_question'].to(device)\n",
    "        }\n",
    "        data = {\n",
    "            'input_ids': batch['input_ids'].to(device),\n",
    "            'attention_mask': batch['attention_mask'].to(device)\n",
    "        }\n",
    "        optimizer.zero_grad()\n",
    "        masked_labels = mask_label_padding(target['input_ids'])\n",
    "        output = model(\n",
    "            input_ids=data['input_ids'],\n",
    "            attention_mask=data['attention_mask'],\n",
    "            labels=masked_labels\n",
    "        )\n",
    "        loss = output[0]\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        if batch_index % LOG_INTERVAL == 0 and batch_index > 0:\n",
    "            cur_loss = total_loss / LOG_INTERVAL\n",
    "            print('| epoch {:3d} | ' \n",
    "                  '{:5d}/{:5d} batches | '\n",
    "                  'loss {:5.2f}'.format(\n",
    "                    epoch, \n",
    "                    batch_index, len(train_loader), \n",
    "                    cur_loss))\n",
    "            save(\n",
    "                SAVED_MODEL_PATH,\n",
    "                epoch, \n",
    "                model.state_dict(), \n",
    "                optimizer.state_dict(), \n",
    "                best_val_loss\n",
    "            )\n",
    "            total_loss = 0\n",
    "\n",
    "def evaluate(eval_model, data_loader):\n",
    "    eval_model.eval()\n",
    "    total_loss = 0.\n",
    "    with torch.no_grad():\n",
    "        for batch_index, batch in tqdm(enumerate(data_loader)):\n",
    "            target = {\n",
    "                'input_ids': batch['input_ids_question'].to(device)\n",
    "            }\n",
    "            data = {\n",
    "                'input_ids': batch['input_ids'].to(device),\n",
    "                'attention_mask': batch['attention_mask'].to(device)\n",
    "            }\n",
    "            masked_labels = mask_label_padding(target['input_ids'])\n",
    "            output = eval_model(\n",
    "                input_ids=data['input_ids'],\n",
    "                attention_mask=data['attention_mask'],\n",
    "                labels=masked_labels\n",
    "            )\n",
    "            total_loss += output[0].item()\n",
    "    return total_loss / len(data_loader)\n",
    "\n",
    "def mask_label_padding(labels):\n",
    "    MASK_ID = -100\n",
    "    labels[labels==tokenizer.pad_token_id] = MASK_ID\n",
    "    return labels\n",
    "\n",
    "def save(path, epoch, model_state_dict, optimizer_state_dict, loss):\n",
    "    torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model_state_dict,\n",
    "            'optimizer_state_dict': optimizer_state_dict,\n",
    "            'best_loss': loss,\n",
    "            }, path)\n",
    "\n",
    "def load(path):\n",
    "    return torch.load(path)\n",
    "\n",
    "def print_line():\n",
    "    LINE_WIDTH = 60\n",
    "    print('-' * LINE_WIDTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9J13rDps2QIu",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c598dbf545804e8b900a22f1108741d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |  5000/62445 batches | loss  2.30\n",
      "| epoch   1 | 10000/62445 batches | loss  2.28\n",
      "| epoch   1 | 15000/62445 batches | loss  2.25\n",
      "| epoch   1 | 20000/62445 batches | loss  2.24\n",
      "| epoch   1 | 25000/62445 batches | loss  2.21\n",
      "| epoch   1 | 30000/62445 batches | loss  2.21\n",
      "| epoch   1 | 35000/62445 batches | loss  2.21\n",
      "| epoch   1 | 40000/62445 batches | loss  2.18\n",
      "| epoch   1 | 45000/62445 batches | loss  2.16\n",
      "| epoch   1 | 50000/62445 batches | loss  2.15\n",
      "| epoch   1 | 55000/62445 batches | loss  2.15\n",
      "| epoch   1 | 60000/62445 batches | loss  2.14\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6fed484619a431b85877ede2bbb5229",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "| end of epoch   1 | valid loss  1.99\n",
      "------------------------------------------------------------\n",
      "| Model saved.\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e956ff72f054a13b1340075406a3ea0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   2 |  5000/62445 batches | loss  2.12\n",
      "| epoch   2 | 10000/62445 batches | loss  2.12\n",
      "| epoch   2 | 15000/62445 batches | loss  2.12\n",
      "| epoch   2 | 20000/62445 batches | loss  2.09\n",
      "| epoch   2 | 25000/62445 batches | loss  2.09\n",
      "| epoch   2 | 30000/62445 batches | loss  2.08\n",
      "| epoch   2 | 35000/62445 batches | loss  2.07\n",
      "| epoch   2 | 40000/62445 batches | loss  2.08\n",
      "| epoch   2 | 45000/62445 batches | loss  2.07\n",
      "| epoch   2 | 50000/62445 batches | loss  2.05\n",
      "| epoch   2 | 55000/62445 batches | loss  2.05\n",
      "| epoch   2 | 60000/62445 batches | loss  2.03\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e62b8239448d417295c1db34ebdb9aca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "| end of epoch   2 | valid loss  1.92\n",
      "------------------------------------------------------------\n",
      "| Model saved.\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f11cbe85f45144e4a77ed8edb30c5295",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   3 |  5000/62445 batches | loss  2.03\n",
      "| epoch   3 | 10000/62445 batches | loss  2.03\n",
      "| epoch   3 | 15000/62445 batches | loss  2.03\n",
      "| epoch   3 | 20000/62445 batches | loss  2.02\n",
      "| epoch   3 | 25000/62445 batches | loss  2.02\n",
      "| epoch   3 | 30000/62445 batches | loss  2.01\n",
      "| epoch   3 | 35000/62445 batches | loss  2.01\n",
      "| epoch   3 | 40000/62445 batches | loss  2.00\n",
      "| epoch   3 | 45000/62445 batches | loss  1.98\n",
      "| epoch   3 | 50000/62445 batches | loss  1.98\n",
      "| epoch   3 | 55000/62445 batches | loss  1.98\n",
      "| epoch   3 | 60000/62445 batches | loss  1.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4f194325862415ba94281d12d072275",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "| end of epoch   3 | valid loss  1.87\n",
      "------------------------------------------------------------\n",
      "| Model saved.\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86cecce5bbc2404186f2c209d80ebc5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   4 |  5000/62445 batches | loss  1.97\n",
      "| epoch   4 | 10000/62445 batches | loss  1.98\n",
      "| epoch   4 | 15000/62445 batches | loss  1.96\n",
      "| epoch   4 | 20000/62445 batches | loss  1.98\n",
      "| epoch   4 | 25000/62445 batches | loss  1.98\n",
      "| epoch   4 | 30000/62445 batches | loss  1.94\n",
      "| epoch   4 | 35000/62445 batches | loss  1.95\n",
      "| epoch   4 | 40000/62445 batches | loss  1.96\n",
      "| epoch   4 | 45000/62445 batches | loss  1.94\n",
      "| epoch   4 | 50000/62445 batches | loss  1.95\n",
      "| epoch   4 | 55000/62445 batches | loss  1.95\n",
      "| epoch   4 | 60000/62445 batches | loss  1.95\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a8b140f1d794175b6227f56f7a0cb7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "| end of epoch   4 | valid loss  1.83\n",
      "------------------------------------------------------------\n",
      "| Model saved.\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "489607dff09641a6813fbbcabac68efd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   5 |  5000/62445 batches | loss  1.93\n",
      "| epoch   5 | 10000/62445 batches | loss  1.94\n",
      "| epoch   5 | 15000/62445 batches | loss  1.94\n",
      "| epoch   5 | 20000/62445 batches | loss  1.93\n",
      "| epoch   5 | 25000/62445 batches | loss  1.94\n",
      "| epoch   5 | 30000/62445 batches | loss  1.92\n",
      "| epoch   5 | 35000/62445 batches | loss  1.93\n",
      "| epoch   5 | 40000/62445 batches | loss  1.91\n",
      "| epoch   5 | 45000/62445 batches | loss  1.92\n",
      "| epoch   5 | 50000/62445 batches | loss  1.90\n",
      "| epoch   5 | 55000/62445 batches | loss  1.93\n",
      "| epoch   5 | 60000/62445 batches | loss  1.91\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "241030fa8ff5454ebb809973bfbc3e05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "| end of epoch   5 | valid loss  1.81\n",
      "------------------------------------------------------------\n",
      "| Model saved.\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f67e69680414fa7b859209705d65202",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   6 |  5000/62445 batches | loss  1.90\n",
      "| epoch   6 | 10000/62445 batches | loss  1.88\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = float(\"inf\")\n",
    "best_model = None\n",
    "\n",
    "saved = load(SAVED_MODEL_PATH)\n",
    "model.load_state_dict(saved[\"model_state_dict\"])\n",
    "optimizer.load_state_dict(saved[\"optimizer_state_dict\"])\n",
    "\n",
    "# val_loss = evaluate(model, valid_loader)\n",
    "# print_line()\n",
    "# print('| Before training | valid loss {:5.2f}'.format(\n",
    "#     val_loss)\n",
    "# )\n",
    "print_line()\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "\n",
    "    train(epoch, best_val_loss)\n",
    "    torch.cuda.empty_cache()\n",
    "    val_loss = evaluate(model, valid_loader)\n",
    "    torch.cuda.empty_cache()\n",
    "    print_line()\n",
    "    print('| end of epoch {:3d} | valid loss {:5.2f}'.format(\n",
    "        epoch,\n",
    "        val_loss)\n",
    "    )\n",
    "    print_line()\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model = model\n",
    "        save(\n",
    "             SAVED_MODEL_PATH,\n",
    "             epoch, \n",
    "             model.state_dict(), \n",
    "             optimizer.state_dict(), \n",
    "             best_val_loss\n",
    "        )\n",
    "        print(\"| Model saved.\")\n",
    "        print_line()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNkFJbYAaLQ9Q2ylMwrLSAk",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "mount_file_id": "1Dv4wvUk6kl0WGFBxf2zb2W_3DDzwBLe8",
   "name": "QG_T5_training.ipynb",
   "provenance": [
    {
     "file_id": "1fjUac5wqsbl4kdfR6XRD0Zor3TfAg-fe",
     "timestamp": 1592456064028
    },
    {
     "file_id": "1y_8MTWmQnKalcdTQNLSZaoWN2KuAmUC5",
     "timestamp": 1591767629922
    },
    {
     "file_id": "1CIlJj2br71COiwuF4ZLWJPnMNgu0Z3u5",
     "timestamp": 1590466302923
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python [conda env:idl_p]",
   "language": "python",
   "name": "conda-env-idl_p-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
